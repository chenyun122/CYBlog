â€ƒâ€ƒåœ¨è§†é¢‘æˆ–è®¡ç®—æœºè§†è§‰æ–¹é¢çš„åº”ç”¨ä¸­ï¼Œæœ‰æ—¶éœ€è¦è¯†åˆ«è§†é¢‘ä¸­çš„ç‰¹å®šç‰©ä½“ã€‚æ¯”å¦‚ç§‘å¹»ç‰‡ã€Šå¤´å·ç©å®¶ã€‹ä¸­ï¼Œåæ´¾çš„æ— äººæœºåœ¨å¯»æ‰¾ä¸»è§’è½¦è¾†æ—¶ï¼Œé€šè¿‡åŒ¹é…ä¹‹å‰æ‹æ‘„çš„è½¦è¾†ç‰¹å¾å›¾ç‰‡æ¥è¯†åˆ«ï¼Œå¹¶è¿½è¸ªæ‰“å‡»ã€‚åœ¨æ–°çš„iOSç‰ˆæœ¬ä¸­ï¼Œå¯ä»¥åˆ©ç”¨CoreML+Visionæ ¹æ®è®­ç»ƒå¥½çš„æ¨¡å‹æ¥è¯†åˆ«ï¼Œä½†æ­¤æ–‡ä»‹ç»çš„æ˜¯åˆ©ç”¨OpenCVåº“çš„Template Matchingæ¥è¯†åˆ«ï¼Œä»¥åº”ä»˜ä¸€äº›ç®€å•çš„åœºåˆã€‚æˆ‘ä»¬æœ€ç»ˆè¦å®ç°çš„æ˜¯åœ¨è§†é¢‘ä¸­è¯†åˆ«è‹¹æœLogoï¼ˆè¿™ä¸ªLogoæ˜¯äº‹å…ˆæ‹å¥½çš„ï¼‰ï¼Œæ•ˆæœå¦‚ä¸‹åŠ¨å›¾æ‰€ç¤ºï¼š

<p align="center" >
  <img src="http://p9f3h0583.bkt.clouddn.com/tp3.gif" alt="template matching" title="template matching" width="325px"/>
</p>


â€ƒâ€ƒæ•´ä¸ªé¡¹ç›®ä¸»è¦é€šè¿‡ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤å®ç°ï¼š  
**â€ƒâ€ƒä¸€. é›†æˆOpenCVæœ€æ–°çš„iOSç‰ˆæœ¬Frameworkï¼›  
â€ƒâ€ƒäºŒ. ä½¿ç”¨AVFoundationè·å–è§†é¢‘æµï¼›  
â€ƒâ€ƒä¸‰. åˆ©ç”¨OpenCVè¿›è¡Œæ¨¡ç‰ˆåŒ¹é…(Template Matching)ï¼›  
â€ƒâ€ƒå››. ç»˜åˆ¶çŸ©å½¢æç¤ºä½ç½®ã€‚**

æƒ³ç›´æ¥çœ‹æºç çš„åŒå­¦å¯ä»¥è®¿é—®Githubä¸­çš„[é¡¹ç›®æºç ][2]ã€‚ä¸‹å®Œæºç è®°å¾—æ‰‹åŠ¨ä¸‹è½½OpenCV framework, å®ƒå¤ªå¤§äº†ï¼Œæ— æ³•ç›´æ¥æ”¾åœ¨é¡¹ç›®ä¸­ï¼Œè€å¸æœºéƒ½æ‡‚ï¼ŒğŸ˜‚  ã€‚
* * *

### ä¸€. é›†æˆOpenCVæœ€æ–°çš„iOSç‰ˆæœ¬Framework

â€ƒâ€ƒå…ˆåœ¨Githubä¸Šä¸‹è½½OpenCVçš„æœ€æ–°Releaseç‰ˆæœ¬ï¼š<https://github.com/opencv/opencv/releases>ã€‚iOSè¯·é€‰æ‹©æ–‡ä»¶opencv-3.4.1-ios-framework.zip(ç‰ˆæœ¬å·å¯èƒ½æ›´æ–°)å¹¶è§£å‹ã€‚ç„¶åæ–°å»ºä¸€ä¸ªåä¸ºTamplateMatchingçš„æ–°iOSé¡¹ç›®ï¼Œå› ä¸ºéœ€è¦ä»¥C++æ–¹å¼è°ƒç”¨OpenCVçš„å‡½æ•°ï¼Œæ‰€ä»¥è¯­è¨€é€‰æ‹©Objective-Cæ›´åŠ æ–¹ä¾¿ä¸€ç‚¹ã€‚æœ€åå°†è§£å‹å¥½çš„opencv2.frameworkæ–‡ä»¶æ‹–åˆ°é¡¹ç›®ä¸­ï¼Œé€‰æ‹©â€œCopy items if neededâ€ã€‚ç”±äºOpenCVéƒ¨åˆ†å®å®šä¹‰å’ŒOCçš„åŒåï¼Œå®¹æ˜“å†²çªï¼Œéœ€è¦åœ¨å¼•å…¥iOSåº“ä¹‹å‰`#import <opencv2/opencv.hpp>`,æ‰€ä»¥å»ºç«‹PCHæ–‡ä»¶å¹¶åœ¨å…¶é¡¶éƒ¨æ·»åŠ ï¼š

    #ifdef __cplusplus
    #import <opencv2/opencv.hpp>
    #endif
    

ä¹‹åå°†é¡¹ç›®ç¼–è¯‘é€šè¿‡ï¼Œå‡†å¤‡å·¥ä½œå®Œæˆã€‚

* * *

### äºŒ. ä½¿ç”¨AVFoundationè·å–è§†é¢‘æµ

â€ƒâ€ƒä½¿ç”¨AVFoundationè·å–è§†é¢‘æµçš„æ–¹æ³•ç½‘ä¸Šå·²æœ‰å¾ˆå¤šï¼Œè¿™é‡Œåªåšç®€å•å®ç°ã€‚ä»ç³»ç»Ÿå±‚é¢çœ‹ï¼Œæˆ‘ä»¬è·å–è§†é¢‘æ•°æ®ä¸»ä½“çš„æ­¥éª¤ä¸ºï¼š1.æ‘„åƒå¤´æ•è·è§†é¢‘æµï¼›2.è¾“å…¥åˆ°ç³»ç»Ÿï¼›3.ç³»ç»Ÿå†è¾“å‡ºåˆ°æˆ‘ä»¬çš„ç±»ä¸­å¤„ç†ã€‚ç›¸å…³çš„ç±»ï¼šå…ˆé€šè¿‡AVCaptureDeviceç±»æä¾›ç”¨äºè§†é¢‘è¾“å…¥çš„è®¾å¤‡ï¼Œç„¶åç»‘å®šåˆ°AVCaptureDeviceInputç±»æ¥æä¾›å…·ä½“çš„è¾“å…¥ã€‚è§†é¢‘æµæ•è·è¡Œä¸ºç”±AVCaptureSessionç±»ç®¡ç†ï¼Œå°†AVCaptureDeviceInputå¯¹è±¡åŠ å…¥åˆ°AVCaptureSessionå¯¹è±¡ä¸­æ¥ä¸ºSessionæä¾›è¾“å…¥ã€‚æœ€åç”±AVCaptureVideoDataOutputç±»æ¥æä¾›è§†é¢‘çš„è¾“å‡ºï¼Œè¾“å‡ºçš„æ•°æ®å°±ç”±æˆ‘ä»¬çš„ç±»æ¥å¤„ç†ã€‚
  åœ¨ä¸Šé¢æ‰€å»ºé¡¹ç›®çš„ViewControllerä¸­ï¼Œæˆ‘ä»¬ç›´æ¥è¿›è¡Œè§†é¢‘æ‹æ‘„å¤„ç†ã€‚ä»£ç å¦‚ä¸‹ï¼š

    #import "ViewController.h"
    #import <AVFoundation/AVFoundation.h>
    
    
    @interface ViewController () <AVCaptureVideoDataOutputSampleBufferDelegate> {
    }
    
    @property (nonatomic,strong) AVCaptureSession *captureSession;
    @property (nonatomic,strong) AVCaptureVideoDataOutput *videoOutput;
    @property (nonatomic,strong) AVCaptureVideoPreviewLayer *videoPreviewLayer;
    
    @end
    
    
    @implementation ViewController
    
    - (void)viewDidLoad {
        [super viewDidLoad];
    
        //æ£€æŸ¥è§†é¢‘æƒé™ï¼Œæœ‰æˆæƒåˆ™å¼€å§‹è§†é¢‘æ•è·
        [self checkAuthorization];
    }
    
    //æ£€æŸ¥è§†é¢‘æƒé™
    - (void)checkAuthorization {
        if ([AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeVideo] == AVAuthorizationStatusAuthorized) {
            [self setupCaptureSession];
        }
        else{
            [AVCaptureDevice requestAccessForMediaType:AVMediaTypeVideo completionHandler:^(BOOL granted) {
                if (granted) {
                    [self setupCaptureSession];
                } else {
                    UIAlertController *alertController = [UIAlertController alertControllerWithTitle:@"æœªæˆæƒæ‹æ‘„è§†é¢‘" message:@"è¯·å‰å¾€ç³»ç»Ÿè®¾ç½®å¼€æ”¾æˆæƒ" preferredStyle:UIAlertControllerStyleAlert];
                    UIAlertAction *okAction = [UIAlertAction actionWithTitle:@"å¥½çš„" style:UIAlertActionStyleCancel handler:^(UIAlertAction * _Nonnull action) {}];
                    [alertController addAction:okAction];
                    [self presentViewController:alertController animated:YES completion:nil];
                }
            }];
        }
    }
    
    //é…ç½®è§†é¢‘å¹¶å¼€å§‹æ•è·
    - (void)setupCaptureSession {
        NSArray *possibleDevices = [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo];
        AVCaptureDevice *videoDevice = [possibleDevices firstObject];
        if (!videoDevice) return;
    
        // åˆ›å»ºSession
        AVCaptureSession *session = [[AVCaptureSession alloc] init];
        [session beginConfiguration];
    
        // æ·»åŠ è¾“å…¥è®¾å¤‡
        NSError *error = nil;
        AVCaptureDeviceInput* input = [AVCaptureDeviceInput deviceInputWithDevice:videoDevice error:&error];
        [session addInput:input];
    
        // æ·»åŠ è¾“å‡º
        self.videoOutput = [[AVCaptureVideoDataOutput alloc] init];
        //æ­¤é¡¹è®¾ç½®å¾ˆé‡è¦ï¼Œåœ¨æˆ‘ä»¬å¤„ç†è§†é¢‘å¸§å›¾ç‰‡ï¼Œéœ€è¦32BGRAæ ¼å¼ã€‚è€Œç³»ç»Ÿé»˜è®¤çš„ä¸ºJPEGæ ¼å¼ï¼Œæ‰€ä»¥éœ€è¦åœ¨æ­¤è®¾ç½®ã€‚
        [self.videoOutput setVideoSettings:@{(id)kCVPixelBufferPixelFormatTypeKey:@(kCVPixelFormatType_32BGRA)}];
        dispatch_queue_t queue = dispatch_queue_create("SampleBufferQueue", NULL);
        [self.videoOutput setSampleBufferDelegate:self queue:queue];
        [session addOutput:self.videoOutput];
    
        // å®Œæˆé…ç½®
        [session commitConfiguration];
        self.captureSession = session;
    
        // æ·»åŠ è§†é¢‘é¢„è§ˆå±‚
        self.videoPreviewLayer = [AVCaptureVideoPreviewLayer layer];
        self.videoPreviewLayer.frame = self.view.layer.bounds;
        self.videoPreviewLayer.session = session;
        [self.view.layer addSublayer:self.videoPreviewLayer];
    
        // å¼€å§‹è§†é¢‘
        [session startRunning];
    }
    
    
    #pragma mark - AVCaptureVideoDataOutputSampleBufferDelegate
    - (void)captureOutput:(AVCaptureOutput *)output didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection {
        //æˆ‘ä»¬åœ¨è¿™é‡Œå¤„ç†è§†é¢‘æ•°æ®ï¼Œç”¨äºè¯†åˆ«ç‰¹å®šç‰©ä½“
    }
    
    @end
    
å®Œæˆè¿™ä¸€æ­¥ï¼Œè¿è¡ŒAPPï¼Œæˆäºˆæ‘„åƒæƒé™ï¼Œä¾¿å¯ä»¥çœ‹åˆ°è§†é¢‘æ‹æ‘„ç”»é¢ã€‚
â€ƒâ€ƒ

* * *

### ä¸‰. åˆ©ç”¨OpenCVè¿›è¡Œæ¨¡æ¿åŒ¹é…(Template Matching)
â€ƒâ€ƒä½¿ç”¨OpenCVè¿›è¡Œæ¨¡ç‰ˆåŒ¹é…æ—¶ï¼Œæˆ‘ä»¬è¦ä¼ ç»™å®ƒä¸€å¼ å¤§å›¾ï¼Œä¸€å¼ å°çš„æ¨¡æ¿å›¾ï¼Œç„¶åå®ƒåœ¨å¤§å›¾ä¸­æ‰¾åˆ°æ¨¡æ¿å›¾ç‰‡çš„ä½ç½®ã€‚å¯¹äºè§†é¢‘çš„æ¯ä¸€å¸§ï¼Œæˆ‘ä»¬éƒ½éœ€è¦è¿›è¡Œä¸€æ¬¡åŒ¹é…ï¼Œç¡®å®šè§†é¢‘ä¸­æ˜¯å¦å­˜åœ¨è¯¥ç‰©ä½“ã€‚æˆ‘ä»¬å»ºç«‹ä¸€ä¸ªç±»æ¥ä¸“é—¨è´Ÿè´£è¿™äº›åŒ¹é…å·¥ä½œï¼Œå‘é¡¹ç›®æ·»åŠ ä¸€ä¸ªç»§æ‰¿è‡ª`NSObject`çš„Cocoa Touch Class,å‘½åä¸º`TemplateMatch`ã€‚å®ƒä¸å…¶ä»–ç±»çš„äº¤äº’å¦‚ä¸‹ï¼š
  

<p align="center" >
  <img src="http://p9f3h0583.bkt.clouddn.com/tp.png" alt="template matching" title="template matching" />
</p>

ç”±äºéœ€è¦ä»¥C++æ–¹å¼è°ƒç”¨OpenCVçš„ç›¸å…³å‡½æ•°ï¼Œæ‰€ä»¥å°†.mæ–‡ä»¶çš„æ‰©å±•åé‡å‘½åä¸º.mmï¼Œæ¥è¿›è¡ŒObjective C++ç¼–ç ã€‚
  
#### 1. æ¨¡æ¿åŒ¹é…ç±»å¤´æ–‡ä»¶
å¤´æ–‡ä»¶å¾ˆç®€å•ï¼Œå°±æ˜¯æä¾›ç”¨äºè®¾ç½®æ¨¡æ¿å›¾ç‰‡çš„å±æ€§ï¼Œå’Œæ‰§è¡ŒåŒ¹é…çš„æ–¹æ³•ï¼š
```
#import <UIKit/UIKit.h>
#import <CoreMedia/CoreMedia.h>


@interface TemplateMatch : NSObject

@property(nonatomic,strong) UIImage *templateImage;     //æ¨¡æ¿å›¾ç‰‡ã€‚ç”±äºåŒ¹é…æ–¹æ³•ä¼šè¢«å¤šæ¬¡è°ƒç”¨ï¼Œæ‰€ä»¥æ¨¡æ¿å›¾ç‰‡é€‚åˆå•æ¬¡è®¾å®šã€‚

//åœ¨Bufferä¸­åŒ¹é…é¢„è®¾çš„æ¨¡æ¿ï¼Œå¦‚æœæˆåŠŸåˆ™è¿”å›ä½ç½®ä»¥åŠåŒºåŸŸå¤§å°ã€‚
//è¿™é‡Œè¿”å›çš„RectåŸºäºAVCapture Metadataçš„åæ ‡ç³»ç»Ÿï¼Œå³å€¼åœ¨0.0-0.1ä¹‹é—´ï¼Œæ–¹ä¾¿AVCaptureVideoPreviewLayerç±»è¿›è¡Œè½¬æ¢ã€‚
- (CGRect)matchWithSampleBuffer:(CMSampleBufferRef)sampleBuffer;

@end
```
â€ƒâ€ƒç”±äºè§†é¢‘ç”±ä¸åŒçš„å¸§ç»„æˆï¼Œè€Œæ¨¡æ¿å›¾ç‰‡åˆ™å›ºå®šä¸å˜ã€‚æ‰€ä»¥æˆ‘ä»¬æä¾›ä¸€ä¸ªå±æ€§æ¥è®¾ç½®æ¨¡æ¿å›¾ç‰‡ï¼Œä¸€æ¬¡è®¾å®Œå³å¯ã€‚è€ŒåŒ¹é…è¡Œä¸ºåˆ™ç”±ä¸€ä¸ªæ–¹æ³•å®ç°ï¼Œæä¾›ç»™å¤–éƒ¨å¤šæ¬¡è°ƒç”¨ã€‚

#### 2. æ¨¡æ¿åŒ¹é…ç±»å®ç°
##### 2.1 å‡†å¤‡å·¥ä½œ
â€ƒâ€ƒOpenCVçš„æ¨¡æ¿åŒ¹é…æœ‰ä¸ªç¼ºé™·ï¼Œå°±æ˜¯å¦‚æœæ¨¡æ¿å›¾ç‰‡å’Œå¤§å›¾çš„æ¯”ä¾‹ç›¸å·®å¤ªå¤§ï¼Œåˆ™æ— æ³•åŒ¹é…åˆ°ã€‚æ¯”å¦‚æˆ‘ä»¬è¦åœ¨1000\*1000åƒç´ çš„å›¾ç‰‡ä¸­ï¼ŒæŸ¥æ‰¾å¤§æ¦‚100\*100åƒç´ å¤§å°çš„ç‰©ä½“ï¼Œä½†æä¾›çš„æ¨¡ç‰ˆå›¾ç‰‡åªæœ‰30\*30ï¼Œé‚£ä¹ˆåŒ¹é…åˆ°çš„æ¦‚ç‡ä¼šå¤§å¤§é™ä½ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦ç¼©æ”¾æ¨¡æ¿å›¾ç‰‡æ¥æé«˜åŒ¹é…æ¦‚ç‡ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨C++æ ‡å‡†åº“å®¹å™¨æ¥å­˜æ”¾å„ä¸ªç¼©æ”¾ç­‰çº§çš„æ¨¡æ¿å›¾ç‰‡,ä»¥åŠç”¨å¹³æ–¹å‡½æ•°æ¥è®¡ç®—å„ä¸ªç­‰çº§ç¼©æ”¾æ¯”ä¾‹ã€‚ç±»å®ç°éƒ¨åˆ†çš„å¼€å¤´å¦‚ä¸‹ï¼š

```
#import "TemplateMatch.h"
#include <vector>
#include <math.h>

using namespace cv;
using namespace std;

@interface TemplateMatch() {
    UIImage *_templateImage;
    vector<Mat> _scaledTempls; //å„ä¸ªç¼©æ”¾ç­‰çº§çš„æ¨¡æ¿å›¾ç‰‡çŸ©é˜µ
}

@end
```

åœ¨ç±»å®ç°çš„å¼€å¤´éƒ¨åˆ†æˆ‘ä»¬å®šä¹‰ä¸€äº›å¸¸é‡ï¼Œä»¥ä¾¿é›†ä¸­è°ƒæ•´è®¡ç®—å‚æ•°ï¼š
```
@implementation TemplateMatch

static const float resizeRatio = 0.35;     //åŸå›¾ç¼©æ”¾æ¯”ä¾‹ï¼Œè¶Šå°æ€§èƒ½è¶Šå¥½ï¼Œä½†è¯†åˆ«åº¦è¶Šä½
static const int maxTryTimes = 4;          //æœªè¾¾åˆ°é¢„å®šè¯†åˆ«åº¦æ—¶ï¼Œå†å°è¯•çš„æ¬¡æ•°é™åˆ¶
static const float acceptableValue = 0.7;  //è¾¾åˆ°æ­¤è¯†åˆ«åº¦æ‰è¢«è®¤ä¸ºæ­£ç¡®
static const float scaleRation = 0.75;     //å½“æ¨¡æ¿æœªè¢«è¯†åˆ«æ—¶ï¼Œå°è¯•æ”¾å¤§/ç¼©å°æ¨¡æ¿ã€‚ æŒ‡å®šæ¯æ¬¡æ¨¡æ¿ç¼©å°çš„æ¯”ä¾‹

//......

@end
```


##### 2.2 å›¾ç‰‡æ•°æ®çš„è½¬æ¢
â€ƒâ€ƒOpenCVç”¨çŸ©é˜µç±»`Mat`æ¥ä»£è¡¨æ‰€å¤„ç†çš„å›¾ç‰‡ï¼Œæ‰€ä»¥éœ€è¦å°†`UIImage`å¯¹è±¡å’Œ`CMSampleBufferRef`æ•°æ®è½¬æ¢ä¸º`Mat`å¯¹è±¡ï¼Œå¹¶å°†é¢œè‰²è°ƒæ•´ä¸ºç°åº¦ä»¥æ›´å¥½åœ°é€‚é…OpenCVçš„ä¸€äº›å‡½æ•°ã€‚åœ¨ç±»å®ç°ä¸­æ·»åŠ ä»¥ä¸‹æ–¹æ³•ï¼š
```
//UIImageè½¬ä¸ºOpenCVç°å›¾çŸ©é˜µ
- (Mat)cvMatGrayFromUIImage:(UIImage *)image {
    Mat img;
    Mat img_color = [self cvMatFromUIImage:image];
    cvtColor(img_color, img, CV_BGR2GRAY);
    
    return img;
}

//UIImageè½¬ä¸ºOpenCVçŸ©é˜µ
- (Mat)cvMatFromUIImage:(UIImage *)image {
    CGColorSpaceRef colorSpace = CGImageGetColorSpace(image.CGImage);
    CGFloat cols = image.size.width;
    CGFloat rows = image.size.height;
    
    Mat cvMat(rows, cols, CV_8UC4); // 8ä½å›¾, 4é€šé“ (é¢œè‰² é€šé“ + alpha)
    
    CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // æ•°æ®æ¥æº
                                                    cols,                       // å®½
                                                    rows,                       // é«˜
                                                    8,                          // 8ä½
                                                    cvMat.step[0],              // æ¯è¡Œå­—èŠ‚
                                                    colorSpace,                 // é¢œè‰²ç©ºé—´
                                                    kCGImageAlphaNoneSkipLast |
                                                    kCGBitmapByteOrderDefault); // Bitmapå›¾ä¿¡æ¯
    
    CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), image.CGImage);
    CGContextRelease(contextRef);
    
    return cvMat;
}

//Bufferè½¬ä¸ºOpenCVçŸ©é˜µ
- (Mat)cvMatFromBuffer:(CMSampleBufferRef)buffer {
    CVImageBufferRef pixelBuffer = CMSampleBufferGetImageBuffer(buffer);
    CVPixelBufferLockBaseAddress( pixelBuffer, 0 );
    
    //å–å¾—é«˜å®½ï¼Œä»¥åŠæ•°æ®èµ·å§‹åœ°å€
    int bufferWidth = (int)CVPixelBufferGetWidth(pixelBuffer);
    int bufferHeight = (int)CVPixelBufferGetHeight(pixelBuffer);
    unsigned char *pixel = (unsigned char *)CVPixelBufferGetBaseAddress(pixelBuffer);
    
    //è½¬ä¸ºOpenCVçŸ©é˜µ
    Mat mat = Mat(bufferHeight,bufferWidth,CV_8UC4,pixel,CVPixelBufferGetBytesPerRow(pixelBuffer));
    
    //ç»“æŸå¤„ç†
    CVPixelBufferUnlockBaseAddress( pixelBuffer, 0 );
    
    //è½¬ä¸ºç°åº¦å›¾çŸ©é˜µ
    Mat matGray;
    cvtColor(mat, matGray, CV_BGR2GRAY);
    
    return matGray;
}
```

##### 2.3 æ¨¡æ¿å›¾ç‰‡å±æ€§çš„è®¾ç½®
â€ƒâ€ƒæ¨¡æ¿å›¾ç‰‡ä¸€æ¬¡è®¾ç½®ï¼Œå¤šæ¬¡å¤ç”¨ã€‚ä¸€äº›å‡†å¤‡æ€§å·¥ä½œä¹Ÿåœ¨è®¾ç½®æ—¶å®Œæˆï¼Œæ¯”å¦‚å„ä¸ªç¼©æ”¾æ¯”ä¾‹çš„ç‰ˆæœ¬ã€‚å¦å¤–ï¼Œå¯¹äºä¸€å¼ iPhoneæ‹æ‘„çš„åŸå›¾ï¼ŒOpenCVæ¨¡æ¿åŒ¹é…çš„æ€§èƒ½å…¶å®å¹¶ä¸é«˜ï¼Œé€šå¸¸ä¼šå ç”¨5-10ç§’çš„æ—¶é—´ã€‚è¿™åœ¨è§†é¢‘æ•è·çš„åº”ç”¨åœºæ™¯ä¸­å»¶æ—¶å¤ªé«˜äº†ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å¯¹æ¨¡æ¿å›¾ç‰‡å’ŒåŸå›¾è¿›è¡ŒåŒæ¯”ä¾‹å‹ç¼©ä»¥æé«˜æ€§èƒ½ã€‚è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªå›¾ç‰‡æ¨ªå±ç«–å±é—®é¢˜ï¼ŒAVFoundationæä¾›çš„è§†é¢‘å¸§é»˜è®¤æ˜¯æ¨ªå±çš„ï¼Œç›¸å½“äºiPhone Homeé”®åœ¨å³ä¾§æ—¶æ‹æ‘„é‚£æ ·ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

<p align="center" >
  <img src="http://p9f3h0583.bkt.clouddn.com/tp_portrait.png" alt="coordinates" title="coordinates" />
</p>
æ‰€ä»¥è¦æŠŠæ¨¡æ¿å›¾ç‰‡é€†æ—¶é’ˆæ—‹è½¬90åº¦ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥åœ¨ViewControllerä¸­æ ¹æ®æ‰‹æœºçš„æ—‹è½¬æƒ…å†µï¼Œå¯¹æ¨¡æ¿å›¾ç‰‡åšç›¸åº”çš„æ—‹è½¬ï¼Œç„¶åæä¾›ç»™TemplateMatchç±»ã€‚è¿™é‡Œå…ˆç®€å•å¤„ç†ä¸‹ï¼Œå°±é»˜è®¤ä¸ºç«–å±æ–¹å¼ã€‚æ¨¡æ¿å›¾ç‰‡å±æ€§è®¾ç½®è¿‡ç¨‹å¦‚ä¸‹ï¼š

```
//è®¾ç½®æ¨¡æ¿å›¾ç‰‡
//ç”±äºæ‹æ‘„ä¼šå­˜åœ¨æ‹‰è¿œæ‹‰è¿‘çš„è¡Œä¸ºï¼Œæ‰€ä»¥éœ€è¦å»ºç«‹ä¸åŒå¤§å°çš„æ¨¡æ¿å›¾ç‰‡ï¼Œè¿›è¡Œå¤šæ¬¡åŒ¹é…
- (void)setTemplateImage:(UIImage *)templateImage {
    //ä¿å­˜é»˜è®¤æ¨¡æ¿å›¾ï¼Œå¹¶å–å¾—æ¨¡æ¿çŸ©é˜µ
    _templateImage = templateImage;
    Mat templUp = [self cvMatGrayFromUIImage:templateImage];
    
    //æœ¬ä¾‹å­é»˜è®¤é‡‡ç”¨ç«–å±æ‹æ‘„ï¼Œè€ŒAVFoundationæä¾›çš„æ•°æ®ä¸ºæ¨ªå±æ¨¡å¼ï¼Œæ‰€ä»¥éœ€è¦å°†æ¨¡æ¿å›¾é€†æ—¶é’ˆæ—‹è½¬90åº¦
    //æ›´å¥½çš„æ–¹å¼ï¼Œæ˜¯åœ¨ViewControllerä¸­æ ¹æ®å±å¹•æ–¹å‘åŠ¨æ€æ—‹è½¬æ¨¡æ¿å›¾,å¹¶é‡æ–°èµ‹å€¼ã€‚è¿™é‡Œæš‚æ—¶ç®€åŒ–å¤„ç†ã€‚
    Mat templ;
    cv::rotate(templUp, templ, ROTATE_90_COUNTERCLOCKWISE);
    
    //è®¾ç½®æ–°æ¨¡æ¿ï¼Œéœ€æ¸…ç©ºæ—§æ¨¡æ¿
    _scaledTempls.clear();
    
    //ä¸ºäº†æé«˜æ€§èƒ½ï¼Œæ¨¡æ¿å›¾å’ŒåŸå›¾è¿›è¡ŒåŒæ¯”åˆ—å‹ç¼©
    Mat templResized;
    resize(templ, templResized, cv::Size(0, 0), resizeRatio, resizeRatio);
    _scaledTempls.push_back(templResized); //é»˜è®¤æ¨¡æ¿å›¾ä¹Ÿå­˜æ”¾äºæ¨¡æ¿æ•°ç»„ä¸­ï¼Œä»¥ä¾¿å¾ªç¯åŒ¹é…
    
    //ç”±äºæ¨¡æ¿å›¾å’ŒåŸå›¾å¤§å°æ¯”ä¾‹ä¸ä¸€è‡´ï¼Œéœ€è¦æ”¾å¤§ç¼©å°æ¨¡æ¿å›¾ï¼Œæ¥å¤šæ¬¡æ¯”è¾ƒã€‚æ‰€ä»¥å»ºç«‹ä¸åŒæ¯”ä¾‹çš„æ¨¡æ¿å›¾ã€‚
    for(int i=0;i<maxTryTimes;i++) {
        //æ”¾å¤§æ¨¡æ¿å›¾
        float powIncreaRation = pow(2 - scaleRation, i+1);
        resize(templ, templResized, cv::Size(0, 0), resizeRatio * powIncreaRation, resizeRatio * powIncreaRation);
        _scaledTempls.push_back(templResized); //ç”±äºpush_backæ–¹æ³•æ‰§è¡Œå€¼æ‹·è´ï¼Œæ‰€ä»¥å¯ä»¥å¤ç”¨templResizedå˜é‡ã€‚
        
        //ç¼©å°æ¨¡æ¿å›¾
        float powReduceRation = pow(scaleRation, i+1);
        resize(templ, templResized, cv::Size(0, 0), resizeRatio * powReduceRation, resizeRatio * powReduceRation);
        _scaledTempls.push_back(templResized);
    }
}
```
##### 2.4 è¿›è¡ŒåŒ¹é…
â€ƒâ€ƒåŒ¹é…æ—¶ï¼Œæˆ‘ä»¬æ¥å—`AVFoundation`æä¾›çš„`CMSampleBufferRef`è§†é¢‘å¸§æ•°æ®ï¼Œç„¶åå°†å®ƒè½¬æ¢æˆ`Mat`çŸ©é˜µã€‚åŒæ¨¡æ¿å›¾ç‰‡ä¸€æ ·ï¼Œå¯¹çŸ©é˜µè¿›è¡Œå‹ç¼©ä»¥æé«˜æ€§èƒ½ã€‚ä¹‹åï¼Œåœ¨ä¸€ä¸ªå¾ªç¯é‡Œä¾æ¬¡å–å‡ºå„ä¸ªç¼©æ”¾ç­‰çº§çš„æ¨¡æ¿å›¾å’Œå¤§å›¾è¿›è¡ŒåŒ¹é…ã€‚ç”±äºAVCapture Metadataçš„åæ ‡ç³»ç»Ÿçš„å€¼èŒƒå›´åœ¨(-1,1)ä¹‹é—´ï¼Œæ‰€ä»¥åœ¨åŒ¹é…æˆåŠŸåï¼Œè¦æŒ‰ä½ç½®åœ¨å›¾ä¸­æ‰€å¤„çš„æ¯”ä¾‹æ¥è¿›è¡Œæ¢ç®—ã€‚è¿™ä¹Ÿæ­£å¥½çœç•¥äº†å°†ä½ç½®ç»å¯¹å€¼è¿˜åŸçš„åˆ°å›¾å‹ç¼©å‰çš„å€¼è¿™æ­¥è®¡ç®—ã€‚ä»£ç å¦‚ä¸‹ï¼š
```
//æ¥å—Bufferè¿›è¡ŒåŒ¹é…
- (CGRect)matchWithSampleBuffer:(CMSampleBufferRef)sampleBuffer {
    Mat img = [self cvMatFromBuffer:sampleBuffer]; //Bufferè½¬æ¢åˆ°çŸ©é˜µ
    
    //å¦‚æœå›¾ç‰‡ä¸ºç©ºï¼Œåˆ™è¿”å›ç©ºå€¼
    if (resizeRatio <= 0 || img.cols <= 0 || img.rows <= 0) {
        return CGRectZero;
    }
    
    //ä¸ºäº†æé«˜æ€§èƒ½ï¼Œå°†åŸå›¾ç¼©å°ã€‚æ¨¡æ¿å›¾ä¹Ÿå·²åŒæ¯”ä¾‹ç¼©å°ã€‚
    Mat imgResized = Mat();
    resize(img, imgResized, cv::Size(0, 0), resizeRatio, resizeRatio);
    
    //è¿›è¡ŒåŒ¹é…
    cv::Rect rect = [self matchWithMat:imgResized];

    //é™¤ä»¥è¡Œåˆ—æ•°å¾—åˆ°ç‚¹ä½ç½®åœ¨å…¨å›¾ä¸­çš„æ¯”ä¾‹ï¼Œè½¬ä¸ºAVCapture Metadataçš„åæ ‡ç³»ç»Ÿ
    CGPoint point = CGPointMake(rect.x / CGFloat(imgResized.cols), rect.y  / CGFloat(imgResized.rows));
    CGSize templSize = CGSizeMake(rect.width / CGFloat(imgResized.cols), rect.height / CGFloat(imgResized.rows));
    
    return CGRectMake(point.x, point.y, templSize.width, templSize.height);
}

//è°ƒç”¨OpenCVè¿›è¡ŒåŒ¹é…
//æ­¤æ–¹æ³•å…·ä½“è§£é‡Šå‚è€ƒOpenCVå®˜æ–¹æ–‡æ¡£: https://docs.opencv.org/3.2.0/de/da9/tutorial_template_matching.html
- (cv::Rect)matchWithMat:(Mat)img {
    double minVal;
    double maxVal;
    cv::Point minLoc;
    cv::Point maxLoc;

    //åŒ¹é…ä¸åŒå¤§å°çš„æ¨¡æ¿å›¾
    for (int i=0; i < _scaledTempls.size(); i++) {
        Mat templ = _scaledTempls[i];
        
        //åˆ›å»ºç»“æœçŸ©é˜µï¼Œç”¨äºå­˜æ”¾å•æ¬¡åŒ¹é…åˆ°çš„ä½ç½®ä¿¡æ¯(å•æ¬¡ä¼šåŒ¹é…åˆ°å¾ˆå¤šï¼Œåé¢æ ¹æ®ä¸åŒç®—æ³•å–æœ€å¤§æˆ–æœ€å°å€¼)
        int result_cols = img.cols - templ.cols + 1;
        int result_rows = img.rows - templ.rows + 1;
        Mat result;
        result.create(result_rows, result_cols, CV_32FC1);
        
        //OpenCVåŒ¹é…
        matchTemplate(img, templ, result, TM_CCOEFF_NORMED);
        
        //æ•´ç†å‡ºæœ¬æ¬¡åŒ¹é…çš„æœ€å¤§æœ€å°å€¼
        minMaxLoc(result, &minVal, &maxVal, &minLoc, &maxLoc, Mat());
        
        //TM_CCOEFF_NORMEDç®—æ³•ï¼Œå–æœ€å¤§å€¼ä¸ºæœ€ä½³åŒ¹é…
        //å½“æœ€å¤§å€¼ç¬¦åˆè¦æ±‚ï¼Œè®¤ä¸ºåŒ¹é…æˆåŠŸ
        if (maxVal >= acceptableValue) {
            NSLog(@"matched point:%d,%d maxVal:%f, tried times:%d",maxLoc.x,maxLoc.y,maxVal,i + 1);
            return cv::Rect(maxLoc,cv::Size(templ.rows,templ.cols));
        }
    }
    
    //æœªåŒ¹é…åˆ°ï¼Œåˆ™è¿”å›ç©ºåŒºåŸŸ
    return cv::Rect();
}
```
#### 3. å›åˆ°ViewController
â€ƒâ€ƒåœ¨TemplateMatchç±»å®Œæˆåï¼Œæˆ‘ä»¬å°±å¯ä»¥å›åˆ°ViewControllerè¿›è¡Œè°ƒç”¨äº†ã€‚å…ˆæ˜¯å¼•å…¥TemplateMatchç±»å¤´æ–‡ä»¶ã€å£°æ˜å¯¹è±¡ã€åˆå§‹åŒ–ç­‰ç­‰ï¼Œç„¶åå°†æ¨¡æ¿å›¾ç‰‡èµ‹ç»™å®ƒã€‚ æ¨¡æ¿å›¾ç‰‡ä¹Ÿæ˜¯ä»äº‹å…ˆæ‹å¥½çš„ç…§ç‰‡ä¸­æˆªå–å‡ºæ¥çš„ã€‚ä»£ç å¦‚ä¸‹(åªåˆ—å‡ºäº†å¢åŠ çš„ä»£ç )ï¼š
```
//......
#import "TemplateMatch.h"

@interface ViewController () <AVCaptureVideoDataOutputSampleBufferDelegate> {
    TemplateMatch *templateMatch;
}

//......

@end

@implementation ViewController

- (void)viewDidLoad {
    //......

    //åˆå§‹åŒ–æ¨¡æ¿åŒ¹é…å¯¹è±¡ï¼Œå¹¶è®¾ç½®æ¨¡æ¿å›¾
    templateMatch = [[TemplateMatch alloc] init];
    templateMatch.templateImage = [UIImage imageNamed:@"apple"];

    //.....
}
```
æ¥ä¸‹æ¥å°±æ˜¯è§†é¢‘æ•è·ä»£ç†æ–¹æ³•ä¸­ï¼Œè¿›è¡Œè°ƒç”¨äº†ï¼š
```
- (void)captureOutput:(AVCaptureOutput *)output didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection {
    CGRect rect = [templateMatch matchWithSampleBuffer:sampleBuffer]; //å°†bufferæäº¤ç»™OpenCVè¿›è¡Œæ¨¡æ¿åŒ¹é…
    dispatch_async(dispatch_get_main_queue(), ^{
        if (!CGRectEqualToRect(rect,CGRectZero)) { //åŒ¹é…æˆåŠŸï¼Œåˆ™ç»˜åˆ¶æ ‡è¯†æ¡†

        }
        else{ //æœªåŒ¹é…åˆ°ï¼Œåˆ™éšè—æ ‡è¯†æ¡†

        }
    });
}
```
å°±è¿™ä¹ˆå‡ è¡Œä»£ç ï¼Œæ˜¯ä¸æ˜¯ä½¿ç”¨èµ·æ¥So easy? :D
* * *

### å››. ç»˜åˆ¶çŸ©å½¢æç¤ºä½ç½®
â€ƒâ€ƒæœ€åï¼Œè¦å°†åŒ¹é…åˆ°ä½ç½®åŒºåŸŸç»˜åˆ¶åˆ°å±å¹•ä¸Šã€‚è¿™é‡Œæˆ‘ä»¬å°±ç®€å•å¢åŠ ä¸€ä¸ªCALayer, ç„¶åè®¾ç½®å¥½çº¢è‰²è¾¹æ¡†ï¼Œå†æ ¹æ®ä½ç½®çš„ä¸åŒè°ƒæ•´ä¸‹Frame, å°±å¯ä»¥æœ‰ä¸€ä¸ªåŠ¨æ€çº¢æ¡†æ¡†äº†ã€‚å…ˆå£°æ˜ä¸€ä¸ªå¯¹è±¡ï¼š
```
@interface ViewController () <AVCaptureVideoDataOutputSampleBufferDelegate> {
    //......
    CALayer *rectangleLayer;
}
```
å†å®šä¹‰ç»˜åˆ¶æ–¹æ³•ï¼š
```
// ç»˜åˆ¶æ ‡è¯†æ¡†
- (void)drawRectangleAtPoint:(CGRect)rect {
    if (rectangleLayer == nil) {
        rectangleLayer = [CALayer layer];
        rectangleLayer.frame = CGRectMake(0, 0, templateMatch.templateImage.size.width, templateMatch.templateImage.size.height);
        [rectangleLayer setBorderWidth:2.0];
        [rectangleLayer setBorderColor:[UIColor.redColor CGColor]];
        [self.view.layer addSublayer:rectangleLayer];
    }
    
    rectangleLayer.frame = CGRectMake(rect.origin.x, rect.origin.y, rect.size.width, rect.size.height);
    rectangleLayer.hidden = NO;
}

// éšè—æ ‡è¯†æ¡†
- (void)hideRectangle {
    rectangleLayer.hidden = YES;
}
```
â€ƒâ€ƒç»ˆäºåˆ°äº†ä¸–ç•Œçš„å°½å¤´ï¼Œæˆ‘ä»¬å†å®Œå–„ä¸‹è§†é¢‘æ•è·ä»£ç†æ–¹æ³•ã€‚ç”±äºè§†é¢‘çš„å°ºå¯¸å’Œå±å¹•å®½é«˜æ¯”ä¸ä¸€å®šä¸€è‡´, å†åŠ ä¸Šç‚¹åæ ‡å¯¹åº”çš„æ˜¯æ¨ªå±æ–¹å¼ï¼Œæ‰€ä»¥ç»˜åˆ¶çº¢æ¡†æ—¶éœ€è¦è¿›è¡Œåæ ‡è½¬æ¢ã€‚è¾›è¿çš„æ˜¯AVFoundationå·²æä¾›ç°æœ‰æ–¹æ³•`rectForMetadataOutputRectOfInterest`æ¥è½¬æ¢ï¼š
```
- (void)captureOutput:(AVCaptureOutput *)output didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection {
    CGRect rect = [templateMatch matchWithSampleBuffer:sampleBuffer]; //å°†bufferæäº¤ç»™OpenCVè¿›è¡Œæ¨¡æ¿åŒ¹é…
    dispatch_async(dispatch_get_main_queue(), ^{
        if (!CGRectEqualToRect(rect,CGRectZero)) { //åŒ¹é…æˆåŠŸï¼Œåˆ™ç»˜åˆ¶æ ‡è¯†æ¡†
            [self drawRectangleAtPoint:[self.videoPreviewLayer rectForMetadataOutputRectOfInterest:rect]]; //ç”±äºè§†é¢‘çš„å°ºå¯¸å’Œå±å¹•å®½é«˜æ¯”ä¸ä¸€å®šä¸€è‡´ï¼Œæ‰€ä»¥å¯¹äºè§†é¢‘ä¸­çš„ä¸€ä¸ªç‚¹åæ ‡ï¼Œéœ€è¦è½¬æ¢åˆ°å±å¹•çš„å¯¹åº”ä½ç½®ä¸­ã€‚
        }
        else{ //æœªåŒ¹é…åˆ°ï¼Œåˆ™éšè—æ ‡è¯†æ¡†
            [self hideRectangle];
        }
    });
}
```

â€ƒâ€ƒè¿™æ ·ä¸€ä¸ªå…³äºTemplate Matchingçš„é¡¹ç›®å°±å®Œæˆäº†ï¼Œæ€»å…±æ‰300è¡Œä¸åˆ°ä»£ç ï¼Œå¾ˆå®¹æ˜“é˜…è¯»å’ŒæŒæ¡ã€‚

æœ¬æ–‡å¯¹åº”[Demoæºç ][2]ä¸‹è½½ã€‚ä¸‹å®Œæºç è®°å¾—æ‰‹åŠ¨ä¸‹è½½OpenCV framework, å®ƒå¤ªå¤§äº†ï¼Œæ— æ³•ç›´æ¥æ”¾åœ¨é¡¹ç›®ä¸­ã€‚  
åŸåˆ›æ–‡ç« ï¼Œå¦‚éœ€è½¬è½½ï¼Œè¯·æ³¨æ˜å‡ºå¤„([https://blog.happyyun.com][1])ï¼Œéå¸¸æ„Ÿè°¢ï¼

 [1]: https://blog.happyyun.com/2018/05/29/opencv-template-matching/
 [2]: https://github.com/chenyun122/TemplateMatching